# CLAUDE.md

Node.js web scraper for 591.com.tw rental monitoring with Discord notifications and local Docker auto-deployment.

## ğŸš€ Quick Commands

```bash
# Development
bun install  # Automatically sets up Git hooks via Husky

# Start development databases
bun run dev:db:start  # PostgreSQL dev & test databases
bun run dev:pgadmin   # Optional: pgAdmin web interface

# Run tests and API
bun test
bun run api

# Usage
bun run crawler.js "https://rent.591.com.tw/list?region=1&kind=0"
bun run crawler.js "URL" 5  # Latest 5 rentals
bun run crawler.js "URL" --notify-mode=none  # No notifications

# Multi-station crawling
bun run crawler.js "URL_WITH_MULTIPLE_STATIONS" --max-concurrent=3 --delay=1500
bun run crawler.js "URL" --no-merge  # Skip merging duplicate properties
bun run crawler.js "URL" --no-station-info  # Hide station processing info

# Docker
bun run deploy:docker
bun run docker:logs

# API
curl -X POST http://localhost:3000/crawl \
  -H "Content-Type: application/json" \
  -H "x-api-key: your-secret-api-key-here" \
  -d '{"url": "URL", "notifyMode": "filtered"}'

# Multi-station API
curl -X POST http://localhost:3000/crawl \
  -H "Content-Type: application/json" \
  -H "x-api-key: your-secret-api-key-here" \
  -d '{
    "url": "URL_WITH_MULTIPLE_STATIONS",
    "notifyMode": "filtered",
    "multiStationOptions": {
      "maxConcurrent": 3,
      "delayBetweenRequests": 1500,
      "enableMerging": true,
      "showStationInfo": false
    }
  }'

# Debug HTML download (production)
# Set SAVE_DEBUG_HTML=true in production to start saving HTML files
curl -X GET http://localhost:3000/debug/html \
  -H "x-api-key: your-secret-api-key-here"

curl -X GET http://localhost:3000/debug/html/crawl-2025-07-26T10-30-00-000Z.html \
  -H "x-api-key: your-secret-api-key-here" \
  -o "production-sample.html"
```

## ğŸ—ï¸ Architecture

**Core modules:**
- `crawler.js` - CLI entry point
- `api.js` - REST API server  
- `lib/crawlService.js` - Main orchestration
- `lib/crawler.js` - Web scraping logic
- `lib/multiStationCrawler.js` - Multi-station handling
- `lib/notification.js` - Discord webhooks
- `lib/Rental.js` - Domain model

**Domain models:**
- `lib/domain/Distance.js` - Distance calculations
- `lib/domain/SearchUrl.js` - URL parsing & manipulation
- `lib/domain/PropertyId.js` - Property identification

**Key features:**
- Multi-station crawler with domain-driven architecture
- Concurrent crawling with semaphore-based rate limiting
- Intelligent property merging and duplicate detection
- Distance-based notification filtering  
- Dependency injection for testing
- CalVer versioning (YYYY.MM.PATCH)

## âš™ï¸ Configuration

```env
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/...
NOTIFICATION_DELAY=1000
API_PORT=3000
API_KEY=your-secret-api-key-here
SAVE_DEBUG_HTML=true   # Save HTML files to /app/debug-html for debugging (production only)
DEBUG_LOGS=false       # Enable/disable debug logging (true/false)
```

**Distance filtering via API only:**
```json
{
  "notifyMode": "filtered",
  "filteredMode": "silent", 
  "filter": {"mrtDistanceThreshold": 800}
}
```

**Multi-station crawling configuration:**
```json
{
  "multiStationOptions": {
    "maxConcurrent": 3,
    "delayBetweenRequests": 1500,
    "enableMerging": true,
    "showStationInfo": false
  }
}
```

## ğŸ§ª Testing

- Native Bun test framework (migrated from Jest)
- **54+ tests** across multiple files, all passing âœ…
- Unit tests: `tests/unit/` (storage, config, CLI, utils, Rental)
- Integration tests: `tests/integration/` (database operations)
- Test helpers: `tests/helpers/` (mock utilities)

**Database Integration Testing:**
```bash
# Development databases (recommended)
bun run dev:db:start             # Start dev & test PostgreSQL containers
bun run dev:db:stop              # Stop development databases
bun run dev:db:reset             # Reset databases (delete all data)
bun run dev:db:logs              # View database logs
bun run dev:pgadmin              # Start pgAdmin (http://localhost:8080)

# Legacy test setup (alternative)
bun run test:postgres:start      # Start PostgreSQL container
bun run test:postgres:setup      # Setup schema
bun run test:postgres:stop       # Cleanup

# All tests
bun test                         # Unit tests only
bun run test:integration         # All integration tests
```

## ğŸ”„ Git Flow å·¥ä½œæµç¨‹

**åˆ†æ”¯ç­–ç•¥ï¼š**
- `main` - Production åˆ†æ”¯ï¼Œé€£çµ GitHub Actions è‡ªå‹•éƒ¨ç½²
- `develop` - é–‹ç™¼åˆ†æ”¯ï¼Œæ—¥å¸¸é–‹ç™¼ä½¿ç”¨

**é–‹ç™¼æµç¨‹ï¼š**
```bash
# 1. åˆ‡æ›åˆ° develop åˆ†æ”¯é€²è¡Œé–‹ç™¼
git checkout develop
git pull origin develop

# 2. å»ºç«‹åŠŸèƒ½åˆ†æ”¯ï¼ˆå¯é¸ï¼‰
git checkout -b feature/new-feature

# 3. é–‹ç™¼å®Œæˆå¾Œæ¨é€åˆ° develop
git checkout develop
git merge feature/new-feature
git push origin develop

# 4. æº–å‚™ç™¼å¸ƒæ™‚ merge åˆ° main
git checkout main
git pull origin main
git merge develop

# 5. æ›´æ–°ç‰ˆè™Ÿä¸¦æ¨é€ï¼ˆè§¸ç™¼éƒ¨ç½²ï¼‰
bun run version:update
git add package.json
git commit -m "chore: bump version to $(cat package.json | grep version | cut -d'"' -f4)"
git push origin main
```

**CI/CD è§¸ç™¼æ¢ä»¶ï¼š**
- æ¨é€åˆ° `main` åˆ†æ”¯ï¼šè§¸ç™¼ CI + GitHub Actions éƒ¨ç½²
- PR åˆ° `main` åˆ†æ”¯ï¼šåƒ…è§¸ç™¼ CI æª¢æŸ¥
- `develop` åˆ†æ”¯ï¼šä¸è§¸ç™¼ CIï¼Œæœ¬åœ°æ¸¬è©¦å³å¯

## ğŸš€ Production Deployment

**ä½¿ç”¨ GitHub Actions + Self-hosted Runner éƒ¨ç½²ï¼š**

```bash
# 1. æ¨é€åˆ° main è§¸ç™¼è‡ªå‹•éƒ¨ç½²
git push origin main

# 2. æŸ¥çœ‹ GitHub Actions éƒ¨ç½²ç‹€æ…‹
# åœ¨ GitHub repo çš„ Actions é é¢ç›£æ§éƒ¨ç½²é€²åº¦

# 3. æŸ¥çœ‹ production server æ—¥èªŒ
# ç™»å…¥ production server æŸ¥çœ‹æ‡‰ç”¨æ—¥èªŒ
docker logs <container-name>

# 4. æ¸¬è©¦ API åŠŸèƒ½
curl -X GET "https://your-domain.com/health"
curl -X DELETE "https://your-domain.com/query/{queryId}/clear?confirm=true" \
  -H "x-api-key: your-api-key"
```

**éƒ¨ç½²é©—è­‰æµç¨‹ï¼š**
```bash
# 1. æ¨é€åˆ° main è§¸ç™¼è‡ªå‹•éƒ¨ç½²
git push origin main

# 2. ç›£æ§ GitHub Actions workflow
# ç¢ºèª CI æ¸¬è©¦é€šéå’Œéƒ¨ç½²æˆåŠŸ

# 3. é©—è­‰è³‡æ–™åº« migration æ˜¯å¦åŸ·è¡Œ
# æŸ¥æ‰¾æ—¥èªŒä¸­çš„è¨Šæ¯ï¼š
# "ğŸš€ Server startup initiated"
# "ğŸ”„ Running database migrations..."
# "âœ… Database migrations completed successfully"

# 4. æ¸¬è©¦ API åŠŸèƒ½æ­£å¸¸
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ crawler.js          # CLI entry
â”œâ”€â”€ api.js              # REST API
â”œâ”€â”€ lib/                # Core modules
â”‚   â”œâ”€â”€ domain/         # Domain models
â”‚   â”œâ”€â”€ crawlService.js # Main orchestration
â”‚   â”œâ”€â”€ crawler.js      # Web scraping
â”‚   â”œâ”€â”€ multiStationCrawler.js  # Multi-station handling
â”‚   â”œâ”€â”€ notification.js # Discord webhooks
â”‚   â””â”€â”€ Rental.js       # Property model
â”œâ”€â”€ tests/              # Test suite
â”‚   â”œâ”€â”€ unit/           # Unit tests
â”‚   â””â”€â”€ integration/    # Integration tests
â”œâ”€â”€ dev/                # Dev scripts
â”œâ”€â”€ samples/            # HTML test samples (parser testing)
â””â”€â”€ scripts/            # Build scripts
```

## ğŸ§  å·¥ä½œè¨˜æ†¶

- æ›´æ–°è¨˜æ†¶ï¼Œé¿å…ç›´æ¥æ“ä½œæœ¬åœ°çš„docker prodç’°å¢ƒï¼Œä¸”è¦éµå¾ªgit flow