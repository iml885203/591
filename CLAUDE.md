# CLAUDE.md

Node.js web scraper for 591.com.tw rental monitoring with Discord notifications.

## ğŸš€ Quick Commands

```bash
# Development
bun install
bun test
bun run api

# Usage
bun run crawler.js "https://rent.591.com.tw/list?region=1&kind=0"
bun run crawler.js "URL" 5  # Latest 5 rentals
bun run crawler.js "URL" --notify-mode=none  # No notifications

# Multi-station crawling
bun run crawler.js "URL_WITH_MULTIPLE_STATIONS" --max-concurrent=3 --delay=1500
bun run crawler.js "URL" --no-merge  # Skip merging duplicate properties
bun run crawler.js "URL" --no-station-info  # Hide station processing info

# Docker
bun run deploy:docker
bun run docker:logs

# API
curl -X POST http://localhost:3000/crawl \
  -H "Content-Type: application/json" \
  -H "x-api-key: your-secret-api-key-here" \
  -d '{"url": "URL", "notifyMode": "filtered"}'

# Multi-station API
curl -X POST http://localhost:3000/crawl \
  -H "Content-Type: application/json" \
  -H "x-api-key: your-secret-api-key-here" \
  -d '{
    "url": "URL_WITH_MULTIPLE_STATIONS",
    "notifyMode": "filtered",
    "multiStationOptions": {
      "maxConcurrent": 3,
      "delayBetweenRequests": 1500,
      "enableMerging": true,
      "showStationInfo": false
    }
  }'

# Debug HTML download (production)
# Set SAVE_DEBUG_HTML=true in production to start saving HTML files
curl -X GET http://localhost:3000/debug/html \
  -H "x-api-key: your-secret-api-key-here"

curl -X GET http://localhost:3000/debug/html/crawl-2025-07-26T10-30-00-000Z.html \
  -H "x-api-key: your-secret-api-key-here" \
  -o "production-sample.html"
```

## ğŸ—ï¸ Architecture

**Core modules:**
- `crawler.js` - CLI entry point
- `api.js` - REST API server  
- `lib/crawlService.js` - Main orchestration
- `lib/crawler.js` - Web scraping logic
- `lib/multiStationCrawler.js` - Multi-station handling
- `lib/notification.js` - Discord webhooks
- `lib/Rental.js` - Domain model

**Domain models:**
- `lib/domain/Distance.js` - Distance calculations
- `lib/domain/SearchUrl.js` - URL parsing & manipulation
- `lib/domain/PropertyId.js` - Property identification

**Key features:**
- Multi-station crawler with domain-driven architecture
- Concurrent crawling with semaphore-based rate limiting
- Intelligent property merging and duplicate detection
- Distance-based notification filtering  
- Dependency injection for testing
- CalVer versioning (YYYY.MM.PATCH)

## âš™ï¸ Configuration

```env
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/...
NOTIFICATION_DELAY=1000
API_PORT=3000
API_KEY=your-secret-api-key-here
SAVE_DEBUG_HTML=true   # Save HTML files to /tmp/debug-html for debugging (production only)
```

**Distance filtering via API only:**
```json
{
  "notifyMode": "filtered",
  "filteredMode": "silent", 
  "filter": {"mrtDistanceThreshold": 800}
}
```

**Multi-station crawling configuration:**
```json
{
  "multiStationOptions": {
    "maxConcurrent": 3,
    "delayBetweenRequests": 1500,
    "enableMerging": true,
    "showStationInfo": false
  }
}
```

## ğŸ§ª Testing

- Native Bun test framework (migrated from Jest)
- **54+ tests** across multiple files, all passing âœ…
- Unit tests: `tests/unit/` (storage, config, CLI, utils, Rental)
- Integration tests: `tests/integration/` (database operations)
- Test helpers: `tests/helpers/` (mock utilities)

**Database Integration Testing:**
```bash
# PostgreSQL integration tests (production database)
bun run test:postgres:start     # Start PostgreSQL container
bun run test:postgres:setup     # Setup schema
bun run test:integration:database # Run database integration tests
bun run test:postgres:stop      # Cleanup

# All tests
bun test                         # Unit tests only
bun run test:integration         # All integration tests
```

## ğŸ”„ Git Flow å·¥ä½œæµç¨‹

**åˆ†æ”¯ç­–ç•¥ï¼š**
- `main` - Production åˆ†æ”¯ï¼Œé€£çµ Railway è‡ªå‹•éƒ¨ç½²
- `develop` - é–‹ç™¼åˆ†æ”¯ï¼Œæ—¥å¸¸é–‹ç™¼ä½¿ç”¨

**é–‹ç™¼æµç¨‹ï¼š**
```bash
# 1. åˆ‡æ›åˆ° develop åˆ†æ”¯é€²è¡Œé–‹ç™¼
git checkout develop
git pull origin develop

# 2. å»ºç«‹åŠŸèƒ½åˆ†æ”¯ï¼ˆå¯é¸ï¼‰
git checkout -b feature/new-feature

# 3. é–‹ç™¼å®Œæˆå¾Œæ¨é€åˆ° develop
git checkout develop
git merge feature/new-feature
git push origin develop

# 4. æº–å‚™ç™¼å¸ƒæ™‚ merge åˆ° main
git checkout main
git pull origin main
git merge develop

# 5. æ›´æ–°ç‰ˆè™Ÿä¸¦æ¨é€ï¼ˆè§¸ç™¼éƒ¨ç½²ï¼‰
bun run version:update
git add package.json
git commit -m "chore: bump version to $(cat package.json | grep version | cut -d'"' -f4)"
git push origin main
```

**CI/CD è§¸ç™¼æ¢ä»¶ï¼š**
- æ¨é€åˆ° `main` åˆ†æ”¯ï¼šè§¸ç™¼ CI + Railway éƒ¨ç½²
- PR åˆ° `main` åˆ†æ”¯ï¼šåƒ…è§¸ç™¼ CI æª¢æŸ¥
- `develop` åˆ†æ”¯ï¼šä¸è§¸ç™¼ CIï¼Œæœ¬åœ°æ¸¬è©¦å³å¯

## ğŸš„ Railway Production Management

**ä½¿ç”¨ Railway CLI ç®¡ç† Production éƒ¨ç½²ï¼š**

```bash
# æŸ¥çœ‹éƒ¨ç½²ç‹€æ…‹
railway status

# æŸ¥çœ‹å¯¦æ™‚æ—¥èªŒï¼ˆç›£æ§éƒ¨ç½²å’Œé‹è¡Œç‹€æ…‹ï¼‰
railway logs
railway logs --follow  # æŒçºŒç›£æ§

# å¼·åˆ¶é‡æ–°éƒ¨ç½²ï¼ˆä½¿ç”¨æœ€æ–°ä»£ç¢¼ï¼‰
railway redeploy

# æŸ¥çœ‹ç’°å¢ƒè®Šæ•¸
railway variables

# è¨­å®šç’°å¢ƒè®Šæ•¸ï¼ˆå¦‚éœ€è¦ï¼‰
railway variables --set "SKIP_DB_OPTIMIZATION=false"

# é€£æ¥åˆ° Production æ•¸æ“šåº«
railway connect
```

**Production é©—è­‰æµç¨‹ï¼š**
```bash
# 1. æ¨é€åˆ° main è§¸ç™¼è‡ªå‹•éƒ¨ç½²
git push origin main

# 2. ç›£æ§éƒ¨ç½²æ—¥èªŒç¢ºèªå„ªåŒ–åŸ·è¡Œ
railway logs --follow

# 3. é©—è­‰æ•¸æ“šåº«å„ªåŒ–æ˜¯å¦åŸ·è¡Œ
# æŸ¥æ‰¾æ—¥èªŒä¸­çš„å„ªåŒ–è¨Šæ¯ï¼š
# "ğŸš€ Railway startup sequence initiated"
# "ğŸš€ Starting database optimization..."
# "âœ… Database optimization completed successfully"

# 4. æ¸¬è©¦ API åŠŸèƒ½
curl -X GET "https://your-railway-domain.railway.app/health"
curl -X DELETE "https://your-railway-domain.railway.app/query/{queryId}/clear?confirm=true" \
  -H "x-api-key: your-api-key"
```

**å¸¸è¦‹å•é¡Œæ’é™¤ï¼š**
- å¦‚æœå„ªåŒ–æ²’åŸ·è¡Œï¼šæª¢æŸ¥ `package.json` ä¸­çš„ `api` è…³æœ¬æ˜¯å¦æ­£ç¢º
- å¦‚æœå‡ºç¾ `databaseStorage` éŒ¯èª¤ï¼šç¢ºèªæ‰€æœ‰ API ç«¯é»éƒ½æ­£ç¢ºåˆå§‹åŒ–æ•¸æ“šåº«
- å¦‚æœéƒ¨ç½²å¡ä½ï¼šä½¿ç”¨ `railway redeploy` å¼·åˆ¶é‡æ–°éƒ¨ç½²

## ğŸ“ Project Structure

```
â”œâ”€â”€ crawler.js          # CLI entry
â”œâ”€â”€ api.js              # REST API
â”œâ”€â”€ lib/                # Core modules
â”‚   â”œâ”€â”€ domain/         # Domain models
â”‚   â”œâ”€â”€ crawlService.js # Main orchestration
â”‚   â”œâ”€â”€ crawler.js      # Web scraping
â”‚   â”œâ”€â”€ multiStationCrawler.js  # Multi-station handling
â”‚   â”œâ”€â”€ notification.js # Discord webhooks
â”‚   â””â”€â”€ Rental.js       # Property model
â”œâ”€â”€ tests/              # Test suite
â”‚   â”œâ”€â”€ unit/           # Unit tests
â”‚   â””â”€â”€ integration/    # Integration tests
â”œâ”€â”€ dev/                # Dev scripts
â”œâ”€â”€ samples/            # HTML samples
â””â”€â”€ scripts/            # Build scripts
```