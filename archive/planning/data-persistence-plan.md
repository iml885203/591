# è³‡æ–™æŒä¹…åŒ–è¨ˆåŠƒ (Data Persistence Plan)

## ğŸ“‹ æ¦‚è¿°

å°‡ 591 çˆ¬èŸ²çš„è³‡æ–™å¾æª”æ¡ˆç³»çµ±é·ç§»åˆ°è³‡æ–™åº«ï¼Œæä¾›æ­·å²è³‡æ–™æŸ¥è©¢ API å’Œè³‡æ–™æ¯”å°åŠŸèƒ½ã€‚

## ğŸ¯ ç›®æ¨™

1. **è³‡æ–™æŒä¹…åŒ–**: æ‰€æœ‰çˆ¬å–è³‡æ–™å„²å­˜åˆ°è³‡æ–™åº«
2. **æ­·å²æŸ¥è©¢**: æä¾› API æŸ¥çœ‹éå»çš„çˆ¬å–è¨˜éŒ„
3. **è³‡æ–™æ¯”å°**: æ¯”è¼ƒä¸åŒæ™‚é–“é»çš„è³‡æ–™è®ŠåŒ–
4. **æ•ˆèƒ½å„ªåŒ–**: é¿å…é‡è¤‡çˆ¬å–ç›¸åŒè³‡æ–™
5. **å…è²»æ–¹æ¡ˆ**: ä½¿ç”¨å…è²»è³‡æ–™åº«æœå‹™

## ğŸ—„ï¸ è³‡æ–™åº«é¸æ“‡

### é¸é …ä¸€: PostgreSQL (æ¨è–¦)

**å…è²»æœå‹™å•†:**
- **Supabase**: 500MB å„²å­˜ç©ºé–“ï¼Œç„¡é™ API è«‹æ±‚
- **Railway**: PostgreSQL æ’ä»¶ï¼Œèˆ‡éƒ¨ç½²æ•´åˆ
- **Neon**: 512MB å…è²»æ–¹æ¡ˆ

**å„ªå‹¢:**
- é—œè¯å¼è³‡æ–™åº«ï¼Œé©åˆè¤‡é›œæŸ¥è©¢
- JSON æ”¯æ´ï¼Œéˆæ´»å„²å­˜æˆ¿å±‹è³‡è¨Š
- å…¨æ–‡æœå°‹åŠŸèƒ½
- æˆç†Ÿçš„ Node.js ç”Ÿæ…‹ç³»çµ±

### é¸é …äºŒ: MongoDB

**å…è²»æœå‹™å•†:**
- **MongoDB Atlas**: 512MB å…è²»å¢é›†

**å„ªå‹¢:**
- NoSQLï¼Œèˆ‡ç¾æœ‰ JSON çµæ§‹ç›¸å®¹
- æ°´å¹³æ“´å±•å®¹æ˜“
- æ–‡ä»¶å‹å„²å­˜é©åˆæˆ¿å±‹è³‡æ–™

## ğŸ“Š è³‡æ–™åº«æ¶æ§‹è¨­è¨ˆ

### è³‡æ–™è¡¨çµæ§‹

```sql
-- çˆ¬å–ä»»å‹™è¨˜éŒ„
CREATE TABLE crawl_sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    url TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    completed_at TIMESTAMP,
    status VARCHAR(20) DEFAULT 'running', -- running, completed, failed
    total_properties INTEGER DEFAULT 0,
    new_properties INTEGER DEFAULT 0,
    updated_properties INTEGER DEFAULT 0,
    multi_station_options JSONB,
    error_message TEXT
);

-- æˆ¿å±‹è³‡æ–™
CREATE TABLE properties (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    property_id VARCHAR(50) UNIQUE NOT NULL, -- 591 æˆ¿å±‹ ID
    title TEXT NOT NULL,
    link TEXT NOT NULL,
    rental_price INTEGER,
    size_info TEXT,
    location_info TEXT,
    metro_distances JSONB, -- [{station: '', distance: '', unit: ''}]
    raw_data JSONB, -- å®Œæ•´çš„åŸå§‹è³‡æ–™
    first_seen_at TIMESTAMP DEFAULT NOW(),
    last_seen_at TIMESTAMP DEFAULT NOW(),
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- æˆ¿å±‹æ­·å²è®Šæ›´è¨˜éŒ„
CREATE TABLE property_changes (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    property_id UUID REFERENCES properties(id),
    crawl_session_id UUID REFERENCES crawl_sessions(id),
    field_name VARCHAR(100), -- 'price', 'status', 'description' etc.
    old_value TEXT,
    new_value TEXT,
    changed_at TIMESTAMP DEFAULT NOW()
);

-- é€šçŸ¥è¨˜éŒ„
CREATE TABLE notifications (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    property_id UUID REFERENCES properties(id),
    crawl_session_id UUID REFERENCES crawl_sessions(id),
    notification_type VARCHAR(50), -- 'new', 'price_change', 'status_change'
    sent_at TIMESTAMP DEFAULT NOW(),
    discord_message_id TEXT,
    success BOOLEAN DEFAULT true
);

-- å»ºç«‹ç´¢å¼•
CREATE INDEX idx_properties_property_id ON properties(property_id);
CREATE INDEX idx_properties_first_seen ON properties(first_seen_at);
CREATE INDEX idx_properties_active ON properties(is_active);
CREATE INDEX idx_crawl_sessions_created ON crawl_sessions(created_at);
CREATE INDEX idx_property_changes_property ON property_changes(property_id);
```

## ğŸ”§ å¯¦ä½œè¨ˆåŠƒ

### Phase 1: è³‡æ–™åº«æ•´åˆå±¤

1. **å»ºç«‹è³‡æ–™åº«é€£ç·šæ¨¡çµ„** (`lib/database/connection.js`)
   ```javascript
   const { Pool } = require('pg');
   
   class DatabaseConnection {
     constructor() {
       this.pool = new Pool({
         connectionString: process.env.DATABASE_URL,
         ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false
       });
     }
   
     async query(text, params) {
       const client = await this.pool.connect();
       try {
         return await client.query(text, params);
       } finally {
         client.release();
       }
     }
   }
   ```

2. **è³‡æ–™å­˜å–å±¤** (`lib/database/`)
   - `PropertyRepository.js` - æˆ¿å±‹è³‡æ–™ CRUD
   - `CrawlSessionRepository.js` - çˆ¬å–ä»»å‹™ç®¡ç†
   - `NotificationRepository.js` - é€šçŸ¥è¨˜éŒ„
   - `AnalyticsRepository.js` - è³‡æ–™åˆ†ææŸ¥è©¢

### Phase 2: è³‡æ–™é·ç§»

1. **å»ºç«‹é·ç§»è…³æœ¬** (`scripts/migrate-to-database.js`)
   ```javascript
   // å°‡ç¾æœ‰ JSON æª”æ¡ˆè³‡æ–™é·ç§»åˆ°è³‡æ–™åº«
   const migrateExistingData = async () => {
     // è®€å– data/previous_data.json
     // è§£æä¸¦å„²å­˜åˆ°è³‡æ–™åº«
     // å»ºç«‹åˆå§‹çˆ¬å–è¨˜éŒ„
   };
   ```

2. **è³‡æ–™é©—è­‰å’Œæ¸…ç†**
   - å»é™¤é‡è¤‡è³‡æ–™
   - é©—è­‰è³‡æ–™å®Œæ•´æ€§
   - å»ºç«‹property_idå°æ‡‰é—œä¿‚

### Phase 3: çˆ¬èŸ²æœå‹™æ•´åˆ

1. **æ›´æ–° `crawlService.js`**
   ```javascript
   const crawlWithPersistence = async (url, options = {}) => {
     // 1. å»ºç«‹ crawl_session
     const session = await CrawlSessionRepository.create(url, options);
     
     try {
       // 2. åŸ·è¡Œçˆ¬å–
       const properties = await crawlProperties(url, options);
       
       // 3. è³‡æ–™æ¯”å°å’Œå„²å­˜
       const { newCount, updatedCount } = await processProperties(properties, session.id);
       
       // 4. æ›´æ–° session ç‹€æ…‹
       await CrawlSessionRepository.complete(session.id, { newCount, updatedCount });
       
       return { sessionId: session.id, newCount, updatedCount };
     } catch (error) {
       await CrawlSessionRepository.markFailed(session.id, error.message);
       throw error;
     }
   };
   ```

2. **æ™ºèƒ½è³‡æ–™æ¯”å°**
   ```javascript
   const processProperties = async (newProperties, sessionId) => {
     let newCount = 0, updatedCount = 0;
     
     for (const property of newProperties) {
       const existing = await PropertyRepository.findByPropertyId(property.propertyId);
       
       if (!existing) {
         // æ–°æˆ¿å±‹
         await PropertyRepository.create(property, sessionId);
         newCount++;
       } else {
         // æª¢æŸ¥è®ŠåŒ–
         const changes = detectChanges(existing, property);
         if (changes.length > 0) {
           await PropertyRepository.update(existing.id, property);
           await PropertyChangeRepository.recordChanges(changes, sessionId);
           updatedCount++;
         }
       }
     }
     
     return { newCount, updatedCount };
   };
   ```

### Phase 4: æ­·å²è³‡æ–™ API

1. **æ–°å¢ API ç«¯é»** (åœ¨ `api.js`)
   ```javascript
   // GET /api/properties - æŸ¥è©¢æˆ¿å±‹åˆ—è¡¨
   app.get('/api/properties', async (req, res) => {
     const { page = 1, limit = 20, search, minPrice, maxPrice } = req.query;
     const properties = await PropertyRepository.search({
       page, limit, search, minPrice, maxPrice
     });
     res.json(properties);
   });
   
   // GET /api/properties/:id/history - æˆ¿å±‹æ­·å²è®Šæ›´
   app.get('/api/properties/:id/history', async (req, res) => {
     const changes = await PropertyChangeRepository.getByPropertyId(req.params.id);
     res.json(changes);
   });
   
   // GET /api/crawl-sessions - çˆ¬å–è¨˜éŒ„
   app.get('/api/crawl-sessions', async (req, res) => {
     const sessions = await CrawlSessionRepository.getRecent();
     res.json(sessions);
   });
   
   // GET /api/analytics/summary - è³‡æ–™çµ±è¨ˆ
   app.get('/api/analytics/summary', async (req, res) => {
     const stats = await AnalyticsRepository.getDashboardStats();
     res.json(stats);
   });
   ```

2. **å»ºç«‹ç°¡å–®çš„å‰ç«¯ä»‹é¢** (`public/dashboard.html`)
   - æ­·å²çˆ¬å–è¨˜éŒ„
   - æˆ¿å±‹è³‡æ–™æœå°‹
   - åƒ¹æ ¼è®ŠåŒ–è¶¨å‹¢åœ–
   - çµ±è¨ˆè³‡è¨Š

## ğŸ“ˆ é€²éšåŠŸèƒ½

### è³‡æ–™åˆ†æ API

```javascript
// åƒ¹æ ¼è¶¨å‹¢åˆ†æ
GET /api/analytics/price-trends?area=ä¿¡ç¾©å€&days=30

// æ–°ç‰©ä»¶çµ±è¨ˆ
GET /api/analytics/new-properties?groupBy=day&days=7

// ç†±é–€å€åŸŸåˆ†æ
GET /api/analytics/popular-areas
```

### æ™ºèƒ½é€šçŸ¥

```javascript
// åŸºæ–¼æ­·å²è³‡æ–™çš„æ™ºèƒ½é€šçŸ¥
const shouldNotify = (property, changes) => {
  // 1. åƒ¹æ ¼å¤§å¹…é™ä½ (>10%)
  // 2. æ–°å¢åˆ°æ”¶è—å€åŸŸ
  // 3. ç¬¦åˆç‰¹å®šæ¢ä»¶çš„æ–°ç‰©ä»¶
  return rules.some(rule => rule.matches(property, changes));
};
```

## ğŸš€ éƒ¨ç½²å’Œè¨­å®š

### ç’°å¢ƒè®Šæ•¸

```env
DATABASE_URL=postgresql://user:password@host:port/database
DATABASE_MAX_CONNECTIONS=10
ENABLE_DATA_PERSISTENCE=true
```

### Docker Compose å¢å¼·

```yaml
version: '3.8'
services:
  crawler-api:
    # ... ç¾æœ‰è¨­å®š
    depends_on:
      - postgres
    environment:
      - DATABASE_URL=postgresql://crawler:password@postgres:5432/crawler_db
  
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: crawler_db
      POSTGRES_USER: crawler
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./sql/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"

volumes:
  postgres_data:
```

## ğŸ¯ å¯¦ä½œæ™‚ç¨‹

| éšæ®µ | é ä¼°æ™‚é–“ | ä¸»è¦ä»»å‹™ |
|------|----------|----------|
| Phase 1 | 3-5 å¤© | è³‡æ–™åº«è¨­è¨ˆã€é€£ç·šå±¤é–‹ç™¼ |
| Phase 2 | 2-3 å¤© | è³‡æ–™é·ç§»ã€æ¸¬è©¦ |
| Phase 3 | 4-6 å¤© | çˆ¬èŸ²æ•´åˆã€è³‡æ–™æ¯”å°é‚è¼¯ |
| Phase 4 | 3-4 å¤© | API é–‹ç™¼ã€å‰ç«¯ä»‹é¢ |
| **ç¸½è¨ˆ** | **12-18 å¤©** | **å®Œæ•´å¯¦ä½œ** |

## âœ… æª¢æŸ¥æ¸…å–®

**æº–å‚™éšæ®µ:**
- [ ] é¸æ“‡è³‡æ–™åº«æœå‹™ (Supabase/Railway)
- [ ] å»ºç«‹è³‡æ–™åº«å¯¦ä¾‹
- [ ] è¨­è¨ˆä¸¦å»ºç«‹è³‡æ–™è¡¨çµæ§‹
- [ ] æº–å‚™æ¸¬è©¦è³‡æ–™

**é–‹ç™¼éšæ®µ:**
- [ ] å¯¦ä½œè³‡æ–™åº«é€£ç·šå±¤
- [ ] å»ºç«‹ Repository æ¨¡å¼
- [ ] é–‹ç™¼è³‡æ–™é·ç§»å·¥å…·
- [ ] æ•´åˆçˆ¬èŸ²æœå‹™
- [ ] å¯¦ä½œæ­·å²è³‡æ–™ API
- [ ] å»ºç«‹ç°¡å–®å‰ç«¯ä»‹é¢

**æ¸¬è©¦éšæ®µ:**
- [ ] å–®å…ƒæ¸¬è©¦ (Repository å±¤)
- [ ] æ•´åˆæ¸¬è©¦ (å®Œæ•´æµç¨‹)
- [ ] æ•ˆèƒ½æ¸¬è©¦ (å¤§é‡è³‡æ–™)
- [ ] è³‡æ–™ä¸€è‡´æ€§é©—è­‰

**éƒ¨ç½²éšæ®µ:**
- [ ] æ›´æ–° Docker é…ç½®
- [ ] ç’°å¢ƒè®Šæ•¸è¨­å®š
- [ ] ç”Ÿç”¢ç’°å¢ƒæ¸¬è©¦
- [ ] æ–‡ä»¶æ›´æ–°

## ğŸ”— ç›¸é—œè³‡æº

- [Supabase æ–‡ä»¶](https://supabase.com/docs)
- [PostgreSQL æœ€ä½³å¯¦è¸](https://wiki.postgresql.org/wiki/Don%27t_Do_This)
- [Node.js pg å¥—ä»¶](https://node-postgres.com/)
- [Repository æ¨¡å¼](https://martinfowler.com/eaaCatalog/repository.html)